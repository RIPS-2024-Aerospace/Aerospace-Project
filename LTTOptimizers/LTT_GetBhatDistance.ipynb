{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Bhattacharya Distance calculated using sample mean, sample covariance, mean of centralized filter and covariance of centralized filter."
      ],
      "metadata": {
        "id": "WjLso_A1Fp_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RIPS-2024-Aerospace/Aerospace-Project.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UD3LvwN-F3E",
        "outputId": "d8b289ed-b234-4905-c3db-9a5bc2663c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aerospace-Project'...\n",
            "remote: Enumerating objects: 512, done.\u001b[K\n",
            "remote: Counting objects: 100% (243/243), done.\u001b[K\n",
            "remote: Compressing objects: 100% (182/182), done.\u001b[K\n",
            "remote: Total 512 (delta 158), reused 93 (delta 61), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (512/512), 31.48 MiB | 7.93 MiB/s, done.\n",
            "Resolving deltas: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "np.random.seed(29)\n",
        "\n",
        "%run \"/content/Aerospace-Project/DiffusionLunarKF.ipynb\"\n",
        "%run \"/content/Aerospace-Project/CentralizedLunarKF.ipynb\"\n",
        "%run \"/content/Aerospace-Project/FilterComparison.ipynb\"\n"
      ],
      "metadata": {
        "id": "ncXJl8CP-ZUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = np.array([[0.2,0.2,0.2,0.2,0.2], [0.5, 0.5, 0, 0,0], [0.5, 0, 0.5, 0,0], [0.5,0,0, 0.5,0],[0.5,0,0,0,0.5]])\n",
        "D = np.array([[3,3,3,3,3], [3, 3, 0, 0,0], [3, 0, 3, 0,0], [3,0,0, 3,0],[3,0,0,0,3]])\n",
        "\n",
        "num_msmts_arr = [0,3,3,3,3]\n",
        "\n",
        "n = len(C)\n",
        "\n",
        "true_biases = np.array([[np.random.normal(0,np.sqrt(12/(c**2))) for _ in range(n)]]).T\n",
        "true_drifts = np.array([[np.random.normal(0,np.sqrt(0.1/(c**2))) for _ in range(n)]]).T\n",
        "# true_drifts = np.array([[0 for _ in range(n)]]).T\n",
        "\n",
        "F = np.array([[1,dt],[0,1]])\n",
        "F_full = np.kron(np.eye(n),F)\n",
        "\n",
        "def get_station_truth(x,id):\n",
        "    return np.array([[x[2*id][0]],[x[2*id+1][0]]])\n",
        "\n",
        "x = c*np.vstack(tuple([np.array([true_biases[i],true_drifts[i]]) for i in range(n)]))\n",
        "\n",
        "# random initial estimates for each node\n",
        "\n",
        "x0 = [np.array([[np.random.normal(0,np.sqrt(12))],[np.random.normal(0,np.sqrt(0.1))]]) for i in range(n)]\n",
        "x0_cf = np.vstack(tuple(x0))\n",
        "# x0 = [np.array([[0],[0]]) for _ in range(n)]\n",
        "\n",
        "P = [100*np.copy(R(1)) for _ in range(n)]\n",
        "P_prev = np.block([[P[i] if i==j else np.zeros((2,2)) for j in range(n)] for i in range(n)])\n",
        "\n",
        "stations = [Station(i) for i in range(n)]\n",
        "\n",
        "filter_initialize(stations,D,x0,P)\n",
        "\n",
        "Q_10x10 = np.kron(np.eye(5),Q)\n",
        "\n",
        "kf = KalmanFilter(A = F_full, H = H_cf, Q = Q_10x10, R = R_cf, P = P_prev, x0 = x0_cf)\n",
        "#For the first iteration these are our cross_links\n",
        "iterations = 50\n",
        "\n",
        "# num_msmts = np.random.randint(0,10,(iterations,5))\n",
        "num_msmts = np.array([[0,3,3,3,3] for _ in range(iterations)])\n",
        "\n",
        "filter_outputs = run_both_filters(iterations, num_msmts,C,F_full,stations,kf, x)\n",
        "\n",
        "errors_df,errors_cf,P_hist_cf,P_hist_df,truth,measurements,predictions_cf,predictions_df = filter_outputs"
      ],
      "metadata": {
        "id": "YovdUJ2M-pC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defined if function is placed in seperate file\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def sample_cov_and_mean(C):\n",
        "    sample_cov = 0\n",
        "    sample_mean = 0\n",
        "    iters = 50 # monte carlo iters\n",
        "    for j in range(iters):\n",
        "      # Variables\n",
        "      T_c = 0.00000009775\n",
        "      f_L1 = 1575420000\n",
        "      N_i = 4\n",
        "      CN0 = 15\n",
        "      B_pll = 0.5\n",
        "      B_fe = 26000000\n",
        "      T = 0.020\n",
        "      d = 0.3\n",
        "      pi = math.pi\n",
        "      c = 299792458\n",
        "      B_dll = 0.5\n",
        "      dt = 7\n",
        "      sigma_uere = 0 # can't find a value for this\n",
        "\n",
        "      # Values from random table in Source 31\n",
        "      # h_0 = 1.4*(10**(-22))\n",
        "      # h_m1 = 2.3*(10**(-26))\n",
        "      # h_m2 = 3.3*(10**(-31))\n",
        "\n",
        "      # Values from sample clocks in Source 30\n",
        "      h_0 = 1.8*(10**(-21))\n",
        "      h_m1 = 6.492*(10**(-22))\n",
        "      h_m2 = 1.37*(10**(-24))\n",
        "\n",
        "      e1 = (h_0/2)*dt + 2*h_m1*(dt*dt) + (2/3)*h_m2*(pi**2)*(dt**3)\n",
        "      e2 = 2*h_m1*dt + h_m2*((pi*dt)**2)\n",
        "      e3 = ((h_0/(2*dt))+ 2*h_m1 + (8/3)*(pi*pi)*h_m2*dt)\n",
        "\n",
        "      Q = (c**2)*np.array([[e1,e2],[e2,e3]])\n",
        "\n",
        "      s_dll = (B_dll/(2*CN0))*(1/(T_c*B_fe))*(1+(1/(T*CN0)))\n",
        "      pr_var = ((c*T_c)**2)*s_dll+ sigma_uere\n",
        "\n",
        "      s_pll = (B_pll/(CN0))*(1+(1/(2*T*CN0)))\n",
        "      prr_var = ((c**2)/((2*pi*f_L1 * T)**2)) * (s_pll)\n",
        "\n",
        "      R = lambda N : np.kron(np.eye(N),np.array([[pr_var,0],[0,prr_var]]))\n",
        "      R_cf = lambda num_msmts: np.kron(np.eye(sum(num_msmts)),R(1))\n",
        "\n",
        "      measure_noise = lambda num_msmts : np.linalg.cholesky(R_cf(num_msmts)) @ np.random.normal(np.array([[0 for _ in range(2*sum(num_msmts))]]).T)\n",
        "      sigma_j = 10**(-16)\n",
        "\n",
        "      # C = np.array([[0.3,0,0.2,0.5,0], [0.5, 0.5, 0, 0,0], [0.5, 0, 0.5, 0,0], [0.5,0,0, 0.5,0],[0.5,0,0,0,0.5]])\n",
        "      D = np.array([[3,3,3,3,3], [3, 3, 0, 0,0], [3, 0, 3, 0,0], [3,0,0, 3,0],[3,0,0,0,3]])\n",
        "\n",
        "      n = len(C)\n",
        "\n",
        "      true_biases = np.array([[np.random.normal(0,np.sqrt(12/(c**2))) for _ in range(n)]]).T\n",
        "      true_drifts = np.array([[np.random.normal(0,np.sqrt(0.1/(c**2))) for _ in range(n)]]).T\n",
        "      # true_drifts = np.array([[0 for _ in range(n)]]).T\n",
        "\n",
        "      F = np.array([[1,dt],[0,1]])\n",
        "      F_full = np.kron(np.eye(n),F)\n",
        "\n",
        "      Q_10x10=np.kron(np.eye(5), Q)\n",
        "\n",
        "      def get_station_truth(x,id):\n",
        "        return np.array([[x[2*id][0]],[x[2*id+1][0]]])\n",
        "\n",
        "      x = c*np.vstack(tuple([np.array([true_biases[i],true_drifts[i]]) for i in range(n)]))\n",
        "\n",
        "      # Random initial estimates for each node\n",
        "      x0 = [np.array([[np.random.normal(0,np.sqrt(12))],[np.random.normal(0,np.sqrt(0.1))]]) for i in range(n)]\n",
        "      x0_cf = np.vstack(tuple(x0))\n",
        "      # x0 = [np.array([[0],[0]]) for _ in range(n)]\n",
        "\n",
        "      P = [100*np.copy(R(1)) for _ in range(n)]\n",
        "      P_prev = np.block([[P[i] if i==j else np.zeros((2,2)) for j in range(n)] for i in range(n)])\n",
        "\n",
        "      stations = [Station(i) for i in range(n)]\n",
        "\n",
        "      filter_initialize(stations,D,x0,P)\n",
        "\n",
        "      kf = KalmanFilter(A = F_full, H = H_cf, Q = Q_10x10, R = R_cf, P = P_prev, x0 = x0_cf)\n",
        "      # For the first iteration these are our cross_links\n",
        "      iterations = 50\n",
        "\n",
        "      # num_msmts = np.random.randint(0,10,(iterations,5))\n",
        "      num_msmts = np.array([num_msmts_arr for _ in range(iterations)])\n",
        "\n",
        "      filter_outputs = run_both_filters(iterations, num_msmts,C,F_full,stations,kf, x)\n",
        "\n",
        "      errors_df,errors_cf,P_hist_cf,P_hist_df,truth,measurements,predictions_cf,predictions_df = filter_outputs\n",
        "\n",
        "      # expectation of full state covariance (without normalizing)\n",
        "      errors_flat = errors_df[-1].flatten()\n",
        "      e = np.outer(errors_flat, errors_flat)\n",
        "      sample_cov = sample_cov + e\n",
        "\n",
        "      # expectation of errors\n",
        "      sample_mean = sample_mean + errors_flat\n",
        "\n",
        "\n",
        "\n",
        "    sample_cov = sample_cov / iters\n",
        "    sample_mean = sample_mean / iters\n",
        "\n",
        "    return sample_mean, sample_cov, P_hist_cf[-1] # RETURNS DKF MEAN, DKF COVARIANCE, CKF COVARIANCE"
      ],
      "metadata": {
        "id": "NzI5UjFg-tk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
        "    # mu1 = mean of diffusion KF\n",
        "    # mu2 = mean of centralized KF\n",
        "    # Sigma1 = covariance of diffusion KF\n",
        "    # Sigma2 = covariance of centralized KF\n",
        "    Sigma = (Sigma1 + Sigma2) / 2\n",
        "    inv_Sigma = np.linalg.inv(Sigma)\n",
        "\n",
        "    term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
        "    term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
        "\n",
        "    return term1 + term2"
      ],
      "metadata": {
        "id": "d2CRkWZM-9N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combines above 2 functions; output = bhat distance, input = adjacency matrix\n",
        "def run_everything(C):\n",
        "  sample_mean, sample_cov, P_cf = sample_cov_and_mean(C)\n",
        "  mu_df = sample_mean\n",
        "  mu_cf = np.zeros(sample_mean.shape, int)\n",
        "  cov_df = sample_cov\n",
        "  cov_cf = P_cf\n",
        "  return(bhattacharyya_distance(mu_df, mu_cf, cov_df, cov_cf))"
      ],
      "metadata": {
        "id": "uRANe0BhCMKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the number of sat measurements to each station\n",
        "def change_sat_measurements(msmts):\n",
        "  global num_msmts_arr\n",
        "  num_msmts_arr = msmts\n"
      ],
      "metadata": {
        "id": "snhIlLip62D3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}