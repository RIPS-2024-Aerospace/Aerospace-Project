{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RIPS-2024-Aerospace/Aerospace-Project/blob/main/PrintedResultsDiscretizedOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTXIizgxxAcl",
        "outputId": "b7614ba7-39c3-4c69-91ec-2132c615e208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Aerospace-Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/RIPS-2024-Aerospace/Aerospace-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "trqsVxFGw8aM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "\n",
        "np.random.seed(163)\n",
        "\n",
        "%run \"/content/Aerospace-Project/Standard Filters/DiffKf.ipynb\"\n",
        "%run \"/content/Aerospace-Project/Standard Filters/KF.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "R7ydojC-fpE9"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self,id,F,G,H,R,Q,x0,P,q): #q = quality (as a percent, 1 = best)\n",
        "        self.id = id\n",
        "        self.F = F\n",
        "        self.G = G\n",
        "        self.H = H\n",
        "        self.R = R\n",
        "        self.Q = Q\n",
        "        self.q = q\n",
        "\n",
        "        #Has an instance for each node\n",
        "        self.x = x0\n",
        "        self.n = len(x0)\n",
        "\n",
        "        self.P = P\n",
        "\n",
        "        self.nbhrs = []\n",
        "        self.nbhr_weights = {}\n",
        "\n",
        "        self.psi = np.copy(x0)\n",
        "\n",
        "    def predict(self):\n",
        "        self.x = self.F@(np.sum([self.nbhr_weights[node.id]*node.psi for node in self.nbhrs],0))\n",
        "        self.P = (self.F@self.P@self.F.T) + (self.G@self.Q@self.G.T)\n",
        "\n",
        "    def update(self, y):\n",
        "        S = lambda node: (node.H @self.P @ node.H.T) + node.R\n",
        "        #Original Code for K\n",
        "        #K = {node.id: self.P@ node.H.T @ np.linalg.inv(S(node)) for node in self.nbhrs}\n",
        "        #We use a solver to avoid inverses:\n",
        "        #K[i]@S = P@H[i].T --> S.T@K[i].T = H[i]@P.T --> cholesky solve for K[i]\n",
        "        K = {node.id:sp.linalg.cho_solve(sp.linalg.cho_factor(S(node).T),(node.H @ self.P.T)).T for node in self.nbhrs}\n",
        "\n",
        "        I = lambda node: y[node.id] - (node.H @self.psi)\n",
        "        self.psi = self.x\n",
        "\n",
        "        for node in self.nbhrs:\n",
        "            self.psi = self.psi+(K[node.id]@I(node))\n",
        "\n",
        "        for node in self.nbhrs:\n",
        "            self.P = (np.eye(self.n,self.n) - K[node.id]@node.H)@self.P\n",
        "\n",
        "\n",
        "class DiffKF:\n",
        "    def __init__(self,C,F,G,H,R,Q,x0,P):\n",
        "\n",
        "        #Number of nodes\n",
        "        self.n = len(x0)\n",
        "\n",
        "        #weighted adjacencey matrix, nodes must be connected to themselves\n",
        "        self.C = C\n",
        "\n",
        "        self.nodes = []\n",
        "        for i in range(self.n):\n",
        "            self.nodes.append(Node(i,F[i],G[i],H[i],R[i],Q[i],x0[i],P[i], 1))\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(self.n):\n",
        "            for j in range(self.n):\n",
        "                if self.C[i][j] != 0:\n",
        "                    self.nodes[i].nbhrs.append(self.nodes[j])\n",
        "                    self.nodes[i].nbhr_weights[j] = C[i][j]\n",
        "\n",
        "    def predict(self): #a.k.a diffusion update\n",
        "        result = []\n",
        "        for node in self.nodes:\n",
        "            node.predict()\n",
        "            result.append(node.x)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "    def update(self, y, nodes = [0,1,2,3,4]): #a.k.a Incremental update\n",
        "        for i,node in enumerate(self.nodes):\n",
        "            if i in nodes:\n",
        "              node.update(y)\n",
        "            else:\n",
        "              node.update(np.zeros_like(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "EG3UwU2szqws"
      },
      "outputs": [],
      "source": [
        "#Convert list of weights at each edge to a numpy adjacency matrix\n",
        "def convert(weights):\n",
        "  #C just is a reference for where we know there are edges in our network\n",
        "  C = np.array([[0.34,0.33, 0, 0, 0.33],[0.33,0.34,0.33,0,0],[0,0.33,0.34,0.33,0],[0,0,0.33,0.34,0.33],[0.33,0,0,0.33,0.34]])\n",
        "\n",
        "  W = []\n",
        "  i = 0\n",
        "  for arr in C:\n",
        "    for val in arr:\n",
        "      if val != 0:\n",
        "        W.append(weights[i])\n",
        "        i += 1\n",
        "      else: W.append(0)\n",
        "  C = np.array([[W[i] for i in range(0,5)], [W[i] for i in range(5,10)], [W[i] for i in range(10,15)], [W[i] for i in range(15,20)], [W[i] for i in range(20,25)]])\n",
        "  return(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "tao3qvwgw8aO"
      },
      "outputs": [],
      "source": [
        "def run_filters(weights, nodes=[1,2,3,4,5]):\n",
        "  dt = 10\n",
        "\n",
        "  C = convert(weights)\n",
        "  C_unweighted = np.array([[1 if x!=0 else 0 for x in row] for row in C])\n",
        "\n",
        "  num_stns = len(C[0])\n",
        "\n",
        "  A = np.array([[1, dt, 0, 0], [0, 1, 0, 0],[0,0,1,dt], [0, 0, 0, 1]])\n",
        "  H = np.array([[1, 0, 0, 0],[0,0,1,0]])\n",
        "\n",
        "  dkf_state_size = len(A)\n",
        "  dkf_measure_size = len(H)\n",
        "\n",
        "  q = 0.001\n",
        "  Q = q*np.array([[(dt**3)/3, (dt**2)/2, 0, 0], [(dt**2)/2, dt, 0, 0],[0,0,(dt**3)/3,(dt**2)/2], [0, 0, (dt**2)/2, dt]])\n",
        "  R = np.array([[4,0],[0,4]])\n",
        "\n",
        "  A_kf = np.kron(np.eye(num_stns),A)\n",
        "  H_kf = np.kron(np.eye(num_stns),H)\n",
        "  Q_kf = np.kron(np.eye(num_stns),Q)\n",
        "  R_kf = np.kron(np.eye(num_stns),R)\n",
        "\n",
        "  kf_state_size = A_kf.shape[0]\n",
        "  kf_measure_size = R_kf.shape[0]\n",
        "\n",
        "  F = [A for _ in range(num_stns)]\n",
        "  G = [np.eye(dkf_state_size) for _ in range(num_stns)]\n",
        "  H_dkf = [H for _ in range(num_stns)]\n",
        "\n",
        "  Q_dkf = [Q for _ in range(num_stns)]\n",
        "  R_dkf = [R for _ in range(num_stns)]\n",
        "\n",
        "  procc_noise_kf = lambda : np.linalg.cholesky(Q_kf) @ np.random.normal(np.array([[0 for _ in range(kf_state_size)]]).T)\n",
        "  measure_noise_kf = lambda : np.linalg.cholesky(R_kf) @ np.random.normal(np.array([[0 for _ in range(kf_measure_size)]]).T)\n",
        "\n",
        "  measure_kf_to_dkf  = lambda z: [np.array([z[dkf_measure_size*i + j] for j in range(dkf_measure_size)]) for i in range(num_stns)]\n",
        "  state_kf_to_dkf = lambda z: [np.array([z[dkf_state_size*i + j] for j in range(dkf_state_size)]) for i in range(num_stns)]\n",
        "\n",
        "  #True Initial\n",
        "  x0_kf = np.array([[np.random.normal(0,np.sqrt(Q_kf[i,i])) for i in range(kf_state_size)]]).T\n",
        "\n",
        "\n",
        "  #Initial Estimate\n",
        "  x_kf = np.array([[np.random.normal(0,5) for i in range(kf_state_size)]]).T\n",
        "  x_dkf = state_kf_to_dkf(x_kf)\n",
        "\n",
        "\n",
        "  P_kf = 10*np.copy(Q_kf)\n",
        "  P_dkf = [10*np.copy(Q) for _ in range(num_stns)]\n",
        "\n",
        "  kf = KalmanFilter(A = A_kf,H = H_kf, Q = Q_kf, R = R_kf,P=P_kf,x0=x_kf)\n",
        "\n",
        "  dkf = DiffKF(C,F,G,H_dkf,R_dkf,Q_dkf,x_dkf,P_dkf)\n",
        "\n",
        "  iters = 60\n",
        "\n",
        "  truth = np.zeros((iters+1,kf_state_size,1))\n",
        "  truth[0] = x0_kf\n",
        "\n",
        "  measurements = np.zeros((iters+1,kf_measure_size,1))\n",
        "  measurements[0] = (H_kf @ x0_kf)+measure_noise_kf()\n",
        "\n",
        "\n",
        "  predictions_kf = np.zeros((iters,kf_state_size,1))\n",
        "  predictions_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
        "\n",
        "  errors_kf = np.zeros((iters,kf_state_size,1))\n",
        "  errors_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
        "\n",
        "  P_hist_kf = np.zeros((iters,kf_state_size,kf_state_size))\n",
        "  P_hist_dkf = np.zeros((iters, num_stns, dkf_state_size,dkf_state_size))\n",
        "\n",
        "\n",
        "  full_system_P_hist = np.zeros((iters,kf_state_size,kf_state_size))\n",
        "  prev_cov = np.block([[np.zeros(P_dkf[0].shape) if i!= j else dkf.nodes[i].P for j in range(num_stns)] for i in range(num_stns)])\n",
        "\n",
        "  def get_diff_cov(prev_cov, Station_cov):\n",
        "\n",
        "      S = lambda i: np.sum([node.H.T @ np.linalg.inv(node.R) @ node.H for node in dkf.nodes[i].nbhrs],axis = 0)\n",
        "\n",
        "      S_full = np.block([[np.zeros(A.shape) if i!= j else S(j) for j in range(num_stns)] for i in range(num_stns)])\n",
        "      H_full = np.kron(np.eye(num_stns),H)\n",
        "      P_full = np.block([[np.zeros(P_dkf[0].shape) if i!= j else Station_cov[j] for j in range(num_stns)] for i in range(num_stns)])\n",
        "      R_full = np.kron(np.eye(num_stns),R)\n",
        "\n",
        "\n",
        "      C_full = np.kron(C,np.eye(dkf_state_size))\n",
        "      A_full = np.kron(C_unweighted, np.eye(dkf_state_size))\n",
        "\n",
        "      # Sigma1\n",
        "      # compute the covariance (equation 32)\n",
        "      F_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns),A)\n",
        "      G_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns),G[0])\n",
        "      D_i = C_full.T @ P_full @ A_full.T @ H_full.T @ np.linalg.inv(R_full)\n",
        "\n",
        "\n",
        "      term1 = (F_i @ prev_cov @ F_i.T)\n",
        "      term2 = G_i @ np.kron(np.ones((num_stns,num_stns)),Q)@G_i.T\n",
        "      term3 = D_i @ R_full@D_i.T\n",
        "\n",
        "      return term1 + term2 + term3\n",
        "\n",
        "  for i in range(iters):\n",
        "\n",
        "      kf.update(measurements[i])\n",
        "      dkf.update(measure_kf_to_dkf(measurements[i]), nodes)\n",
        "\n",
        "      predictions_dkf[i] = [dkf.nodes[j].x for j in range(num_stns)]\n",
        "      errors_dkf[i] = [dkf.nodes[j].x-state_kf_to_dkf(truth[i])[j] for j in range(num_stns)]\n",
        "      station_covs = [dkf.nodes[j].P for j in range(num_stns)]\n",
        "      P_hist_dkf[i] = station_covs\n",
        "\n",
        "      prev_cov = get_diff_cov(prev_cov, station_covs)\n",
        "      full_system_P_hist[i] = prev_cov\n",
        "\n",
        "      predictions_kf[i] = kf.x\n",
        "      errors_kf[i] = kf.x-truth[i]\n",
        "      P_hist_kf[i] = kf.P\n",
        "\n",
        "      kf.predict()\n",
        "      dkf.predict()\n",
        "\n",
        "      truth[i+1] = A_kf@x0_kf + procc_noise_kf()\n",
        "      measurements[i+1] = H_kf @ truth[i+1] + measure_noise_kf()\n",
        "\n",
        "  mu1 = np.zeros(kf_state_size,int)\n",
        "  mu2 = np.zeros(kf_state_size, int)\n",
        "  bhat = bhattacharyya_distance(mu1, mu2, full_system_P_hist[40], P_hist_kf[40])\n",
        "  return(bhat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "OLXAn2WOw8aP"
      },
      "outputs": [],
      "source": [
        "def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
        "    # mu1 = mean of diffusion KF\n",
        "    # mu2 = mean of centralized KF\n",
        "    # Sigma1 = covariance of diffusion KF\n",
        "    # Sigma2 = covariance of centralized KF\n",
        "    Sigma = (Sigma1 + Sigma2) / 2\n",
        "    inv_Sigma = np.linalg.inv(Sigma)\n",
        "\n",
        "    term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
        "    term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
        "\n",
        "    return term1 + term2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Uz4-gvw5_pcx"
      },
      "outputs": [],
      "source": [
        "#Discretize to get possible weights at any given row\n",
        "def generate_possible_row_weights(n):\n",
        "    row_weights = []\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        for k in range(n):\n",
        "          w1 = round((1/n)*i, 3)\n",
        "          w2 = round((1/n)*j, 3)\n",
        "          w3 = round((1/n)*k, 3)\n",
        "          W = [w1, w2, w3]\n",
        "          s = sum(W)\n",
        "          if s >= 1:\n",
        "              row_weights.append([round(w/s, 3) for w in W])\n",
        "    return row_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "G6dwB7ZsHDTz"
      },
      "outputs": [],
      "source": [
        "#Generate possible weights for the whole network given options for row weights\n",
        "#k = number of rows in our network's adjacency matrix\n",
        "def recurse(weights, index, k, current=[], combs=[]):\n",
        "  if len(combs) == len(weights)**k:\n",
        "    return combs\n",
        "  if index==k:\n",
        "    combs.append(current)\n",
        "  else:\n",
        "    for w in weights:\n",
        "      recurse(weights, index+1, k, current+w, combs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "BvJ2BAE9AsgT"
      },
      "outputs": [],
      "source": [
        "#Grid search approach\n",
        "def grid_search(nodes=[1,2,3,4,5]):\n",
        "  r = generate_possible_row_weights(2)\n",
        "  options = recurse(r, 0, 5)\n",
        "  d = dict()\n",
        "  for w in options:\n",
        "    d[tuple(w)] = run_filters(w, nodes)\n",
        "  sorted_strats = sorted(d.items(), key=lambda x:x[1])\n",
        "  best_response = sorted_strats[0][0]\n",
        "  print(best_response)\n",
        "  print(run_filters(best_response, nodes))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search()"
      ],
      "metadata": {
        "id": "NtpEK3RlUHhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Optimal Weights:\")\n",
        "best_response = [0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.333, 0.333, 0.333, 0.5, 0.5, 0.0]\n",
        "print(convert(best_response))\n",
        "print(\"Minimum Bhattacharya Distance (using these weights):\", run_filters(best_response))\n",
        "print(\"\\nEqual Weights:\")\n",
        "equal = [0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33, 0.33]\n",
        "print(convert(equal))\n",
        "print(\"Bhattacharya Distance using equal weights:\", run_filters(equal))\n",
        "print(\"\\nMinimized-MSE Weights:\")\n",
        "mse = [0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.0]\n",
        "print(convert(mse))\n",
        "print(\"Bhattacharya Distance using these weights:\", run_filters(mse))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZYQrdLlCea8",
        "outputId": "e6924754-4cbb-4c94-dd9c-b0cb79349070"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Weights:\n",
            "[[0.    0.5   0.    0.    0.5  ]\n",
            " [0.    0.5   0.5   0.    0.   ]\n",
            " [0.    0.5   0.    0.5   0.   ]\n",
            " [0.    0.    0.333 0.333 0.333]\n",
            " [0.5   0.    0.    0.5   0.   ]]\n",
            "Minimum Bhattacharya Distance (using these weights): 11.631156754889203\n",
            "\n",
            "Equal Weights:\n",
            "[[0.33 0.33 0.   0.   0.33]\n",
            " [0.33 0.33 0.33 0.   0.  ]\n",
            " [0.   0.33 0.33 0.33 0.  ]\n",
            " [0.   0.   0.33 0.33 0.33]\n",
            " [0.33 0.   0.   0.33 0.33]]\n",
            "Bhattacharya Distance using equal weights: 22.44779087394269\n",
            "\n",
            "Minimized-MSE Weights:\n",
            "[[0.  0.5 0.  0.  0.5]\n",
            " [0.5 0.  0.5 0.  0. ]\n",
            " [0.  0.5 0.  0.5 0. ]\n",
            " [0.  0.  0.5 0.  0.5]\n",
            " [0.5 0.  0.  0.5 0. ]]\n",
            "Bhattacharya Distance using these weights: 13.962013029208437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Minimizing MSE Approach\n",
        "def min_mse():\n",
        ""
      ],
      "metadata": {
        "id": "0gtq3ZE3UJvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "47zRdajXzveL",
        "outputId": "54c15b34-9631-45c2-be87-a3bef0239731"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import scipy as sp\\nfrom scipy.optimize import minimize\\n\\ndef cost_func(diffusion_weights):\\n  return run_filters(diffusion_weights)\\n\\n\\ndef run_optimize():\\n  C = np.array([[0.34,0.33, 0, 0, 0.33],[0.33,0.34,0.33,0,0],[0,0.33,0.34,0.33,0],[0,0,0.33,0.34,0.33],[0.33,0,0,0.33,0.34]])\\n  weights = []\\n  for arr in C:\\n    for val in arr:\\n      if val != 0:\\n        weights.append(val)\\n\\n  run_filters(weights)\\n  x0 = np.array(weights)\\n  bounds = sp.optimize.Bounds(lb = np.zeros(len(weights)), ub = np.ones(len(weights)))\\n  result = sp.optimize.minimize(cost_func, x0, method='BFGS', bounds = bounds)\\n  print(result.x)\""
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#OLD BFGS Code\n",
        "\"\"\"import scipy as sp\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def cost_func(diffusion_weights):\n",
        "  return run_filters(diffusion_weights)\n",
        "\n",
        "\n",
        "def run_optimize():\n",
        "  C = np.array([[0.34,0.33, 0, 0, 0.33],[0.33,0.34,0.33,0,0],[0,0.33,0.34,0.33,0],[0,0,0.33,0.34,0.33],[0.33,0,0,0.33,0.34]])\n",
        "  weights = []\n",
        "  for arr in C:\n",
        "    for val in arr:\n",
        "      if val != 0:\n",
        "        weights.append(val)\n",
        "\n",
        "  run_filters(weights)\n",
        "  x0 = np.array(weights)\n",
        "  bounds = sp.optimize.Bounds(lb = np.zeros(len(weights)), ub = np.ones(len(weights)))\n",
        "  result = sp.optimize.minimize(cost_func, x0, method='BFGS', bounds = bounds)\n",
        "  print(result.x)\"\"\"\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}