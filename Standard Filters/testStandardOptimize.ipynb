{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "np.random.seed(163)\n",
    "\n",
    "%run \"DiffKf.ipynb\"\n",
    "%run \"KF.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10\n",
    "\n",
    "C = np.array([[0.34,0.33, 0, 0, 0.33],[0.33,0.34,0.33,0,0],[0,0.33,0.34,0.33,0],[0,0,0.33,0.34,0.33],[0.33,0,0,0.33,0.34]])\n",
    "C_unweighted = np.array([[1 if x!=0 else 0 for x in row] for row in C])\n",
    "\n",
    "num_stns = len(C[0])\n",
    "\n",
    "A = np.array([[1, dt, 0, 0], [0, 1, 0, 0],[0,0,1,dt], [0, 0, 0, 1]])\n",
    "H = np.array([[1, 0, 0, 0],[0,0,1,0]])\n",
    "\n",
    "dkf_state_size = len(A)\n",
    "dkf_measure_size = len(H)\n",
    "\n",
    "q = 0.001\n",
    "Q = q*np.array([[(dt**3)/3, (dt**2)/2, 0, 0], [(dt**2)/2, dt, 0, 0],[0,0,(dt**3)/3,(dt**2)/2], [0, 0, (dt**2)/2, dt]])\n",
    "R = np.array([[4,0],[0,4]])\n",
    "\n",
    "A_kf = np.kron(np.eye(num_stns),A)\n",
    "H_kf = np.kron(np.eye(num_stns),H)\n",
    "Q_kf = np.kron(np.eye(num_stns),Q)\n",
    "R_kf = np.kron(np.eye(num_stns),R)\n",
    "\n",
    "kf_state_size = A_kf.shape[0]\n",
    "kf_measure_size = R_kf.shape[0]\n",
    "\n",
    "F = [A for _ in range(num_stns)]\n",
    "G = [np.eye(dkf_state_size) for _ in range(num_stns)]\n",
    "H_dkf = [H for _ in range(num_stns)]\n",
    "\n",
    "Q_dkf = [Q for _ in range(num_stns)]\n",
    "R_dkf = [R for _ in range(num_stns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procc_noise_kf = lambda : np.linalg.cholesky(Q_kf) @ np.random.normal(np.array([[0 for _ in range(kf_state_size)]]).T)\n",
    "measure_noise_kf = lambda : np.linalg.cholesky(R_kf) @ np.random.normal(np.array([[0 for _ in range(kf_measure_size)]]).T)\n",
    "\n",
    "measure_kf_to_dkf  = lambda z: [np.array([z[dkf_measure_size*i + j] for j in range(dkf_measure_size)]) for i in range(num_stns)]\n",
    "state_kf_to_dkf = lambda z: [np.array([z[dkf_state_size*i + j] for j in range(dkf_state_size)]) for i in range(num_stns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True Initial\n",
    "x0_kf = np.array([[np.random.normal(0,np.sqrt(Q_kf[i,i])) for i in range(kf_state_size)]]).T\n",
    "\n",
    "\n",
    "#Initial Estimate\n",
    "x_kf = np.array([[np.random.normal(0,5) for i in range(kf_state_size)]]).T\n",
    "x_dkf = state_kf_to_dkf(x_kf)\n",
    "\n",
    "\n",
    "P_kf = 10*np.copy(Q_kf)\n",
    "P_dkf = [10*np.copy(Q) for _ in range(num_stns)]\n",
    "\n",
    "kf = KalmanFilter(A = A_kf,H = H_kf, Q = Q_kf, R = R_kf,P=P_kf,x0=x_kf)\n",
    "\n",
    "dkf = DiffKF(C,F,G,H_dkf,R_dkf,Q_dkf,x_dkf,P_dkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iters = 60\n",
    "\n",
    "truth = np.zeros((iters+1,kf_state_size,1))\n",
    "truth[0] = x0_kf\n",
    "\n",
    "measurements = np.zeros((iters+1,kf_measure_size,1))\n",
    "measurements[0] = (H_kf @ x0_kf)+measure_noise_kf()\n",
    "\n",
    "\n",
    "predictions_kf = np.zeros((iters,kf_state_size,1))\n",
    "predictions_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
    "\n",
    "errors_kf = np.zeros((iters,kf_state_size,1))\n",
    "errors_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
    "\n",
    "P_hist_kf = np.zeros((iters,kf_state_size,kf_state_size))\n",
    "P_hist_dkf = np.zeros((iters, num_stns, dkf_state_size,dkf_state_size))\n",
    "full_system_P_hist = np.zeros((iters,kf_state_size,kf_state_size))\n",
    "\n",
    "for i in range(iters):\n",
    "\n",
    "    kf.update(measurements[i])\n",
    "    dkf.update(measure_kf_to_dkf(measurements[i]))\n",
    "\n",
    "    predictions_dkf[i] = [dkf.nodes[j].x for j in range(num_stns)]\n",
    "    errors_dkf[i] = [dkf.nodes[j].x-state_kf_to_dkf(truth[i])[j] for j in range(num_stns)]\n",
    "    P_hist_dkf[i] = [dkf.nodes[j].P for j in range(num_stns)]\n",
    "\n",
    "    predictions_kf[i] = kf.x\n",
    "    errors_kf[i] = kf.x-truth[i]\n",
    "    P_hist_kf[i] = kf.P\n",
    "\n",
    "    kf.predict()\n",
    "    dkf.predict()\n",
    "\n",
    "    truth[i+1] = A_kf@x0_kf + procc_noise_kf()\n",
    "    measurements[i+1] = H_kf @ truth[i+1] + measure_noise_kf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = -1*((-1*kf_state_size)//2)\n",
    "fig,axs = plt.subplots(num_rows,2, figsize=(14, 7*num_rows))\n",
    "t_hist_dkf = np.arange(0, dt*iters, dt)\n",
    "t_hist_kf = np.arange(dt/2, dt*iters, dt)\n",
    "\n",
    "for i in range(kf_state_size):\n",
    "    axs[i//2][i%2].plot(t_hist_dkf, errors_dkf[:, i//num_stns,i%dkf_state_size,0], 'k', label = f\"Diffusion Filter state {i+1} error\")\n",
    "    dkf_cov = np.sqrt(P_hist_dkf[:, i//num_stns,i%dkf_state_size,i%dkf_state_size])\n",
    "    axs[i//2][i%2].plot(np.vstack([t_hist_dkf[0], t_hist_dkf[0]]), np.vstack([dkf_cov[0], -dkf_cov[0]]), 'b--', label = \"Diffusion Filter 1-sigma bound\")\n",
    "    axs[i//2][i%2].plot(np.vstack([t_hist_dkf[1:], t_hist_dkf[1:]]), np.vstack([dkf_cov[1:], -dkf_cov[1:]]), 'b--')\n",
    "    kf_error = errors_kf[:, i,0]\n",
    "    kf_cov = np.sqrt(P_hist_kf[:, i, i])\n",
    "    axs[i//2][i%2].plot(t_hist_kf, kf_error,'m',label=f'Centralized Filter state {i+1} error')\n",
    "    axs[i//2][i%2].plot(np.vstack([t_hist_kf[0], t_hist_kf[0]]), np.vstack([kf_cov[0], -kf_cov[0]]), 'r--',label = \"Centralized Bias 1-sigma bound\")\n",
    "    axs[i//2][i%2].plot(np.vstack([t_hist_kf[1:], t_hist_kf[1:]]), np.vstack([kf_cov[1:], -kf_cov[1:]]), 'r--')\n",
    "    axs[i//2][i%2].legend()\n",
    "    axs[i//2][i%2].set_title(\"State Element \"+str(i+1)+\" Error\", fontsize = 20)\n",
    "    axs[i//2][i%2].set_xlabel(\"Time\", fontsize = 18)\n",
    "    axs[i//2][i%2].set_ylabel(\"Estimate vs True Bias Error\", fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
    "    # mu1 = mean of diffusion KF\n",
    "    # mu2 = mean of centralized KF\n",
    "    # Sigma1 = covariance of diffusion KF\n",
    "    # Sigma2 = covariance of centralized KF\n",
    "    Sigma = (Sigma1 + Sigma2) / 2\n",
    "    inv_Sigma = np.linalg.inv(Sigma)\n",
    "\n",
    "    term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
    "    term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
    "\n",
    "    return term1 + term2\n",
    "\n",
    "# centralized\n",
    "mu2 = kf.x\n",
    "Sigma2 = kf.P\n",
    "\n",
    "# diffusion\n",
    "# mu1\n",
    "n_i1 = np.random.normal(loc=0, scale=1, size=m)\n",
    "v_i = np.random.normal(loc=0, scale=1, size=m)\n",
    "tilde_x_i_i1 = truth[0]\n",
    "\n",
    "\n",
    "S = lambda i: np.sum([node.H.T @ np.linalg.inv(node.R) @ node.H for node in DKF.nodes[i].nbhrs],axis = 0)\n",
    "\n",
    "S_full = np.block([[np.zeros(H.shape) if i!= j else S(j) for j in range(num_stns)] for i in range(num_stns)])\n",
    "H_full = np.kron(np.eye(num_stns),H_dkf)\n",
    "P_full = lambda iter: np.block([[np.zeros(P_dkf[0].shape) if i!= j else P_hist_dkf[iter][j] for j in range(num_stns)] for i in range(num_stns)])\n",
    "R_full = np.kron(np.eye(num_stns),R)\n",
    "\n",
    "\n",
    "C_full = np.kron(C,np.eye(dkf_state_size))\n",
    "A_full = np.kron(C_unweighted, np.eye(dkf_state_size))\n",
    "\n",
    "# compute the state (equation 30)\n",
    "term1 = np.dot(C.T, np.dot(np.identity(20) - np.dot(P_dkf, S_i), np.dot(np.kron(np.identity(20), F), tilde_x_i_i1)))\n",
    "term2 = np.dot(np.kron(np.identity(20), G), np.kron(np.ones((20,20)), n_i1))\n",
    "term3 = np.dot(C.T, np.dot(P_dkf, np.dot(H_n.T, np.dot(np.linalg.inv(R_dkf), v_i))))\n",
    "mu1 = term1 + term2 - term3\n",
    "\n",
    "# Sigma1\n",
    "# compute the covariance (equation 32)\n",
    "F_i = lambda i: C_full.T @ (np.eye(S_full.shape[1]) - (P_full(i) @ S_full)) @ np.kron(np.eye(num_stns),A)\n",
    "G_i = lambda i: C_full.T @ (np.eye(S_full.shape[1]) - (P_full(i) @ S_full)) @ np.kron(np.eye(num_stns),G[0])\n",
    "D_i = np.dot(C.T, np.dot(P_dkf, np.dot(H_n.T, np.linalg.inv(R_dkf))))\n",
    "D_i = lambda i: C_full.T @ P_full(i) @ A_full.T @ H_full.T @ np.linalg.inv(R_full)\n",
    "\n",
    "\n",
    "term1 = lambda i: F_i(i)\n",
    "term2 = np.dot(G_i, np.dot(np.kron(np.ones((1, 1)), Q_dkf), G_i.T))\n",
    "term3 = np.dot(D_i, np.dot(R_dkf, D_i.T))\n",
    "\n",
    "Sigma1 = term1 + term2 + term3\n",
    "\n",
    "# compute the Bhattacharya distance\n",
    "print(\"The Bhattacharya Distance is: \", bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
