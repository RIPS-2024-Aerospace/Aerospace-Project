{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RIPS-2024-Aerospace/Aerospace-Project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IXu0aYVeFGL",
        "outputId": "b5056d12-25d2-4193-8014-f97405c9ea43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aerospace-Project'...\n",
            "remote: Enumerating objects: 389, done.\u001b[K\n",
            "remote: Counting objects: 100% (120/120), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 389 (delta 91), reused 59 (delta 51), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (389/389), 23.72 MiB | 11.88 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hGnG9B_pd-e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "\n",
        "np.random.seed(163)\n",
        "\n",
        "# replace with file paths\n",
        "# %run \"DiffKf.ipynb\"\n",
        "# %run \"KF.ipynb\"\n",
        "%run \"/content/Aerospace-Project/Standard Filters/DiffKf.ipynb\"\n",
        "%run \"/content/Aerospace-Project/Standard Filters/KF.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MONTE CARLO: COMPARISON OF MINIMIZING TRACE VS MINIMIZING B DISTANCE"
      ],
      "metadata": {
        "id": "WiIHJPLNhrJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# Bhattacharyya distance function\n",
        "# def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
        "#     Sigma = (Sigma1 + Sigma2) / 2\n",
        "#     inv_Sigma = np.linalg.inv(Sigma)\n",
        "#     term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
        "#     term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
        "#     return term1 + term2\n",
        "\n",
        "\n",
        "# since the means are 0, I'm getting rid of the first term\n",
        "def bhattacharyya_distance(Sigma1, Sigma2):\n",
        "    Sigma_mean = (Sigma1 + Sigma2) / 2\n",
        "    term1 = np.log(np.linalg.det(Sigma_mean) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2))) / 2\n",
        "    return term1\n",
        "\n",
        "# Function to get diffusion covariance\n",
        "def get_diff_cov(prev_cov, Station_cov, dkf, num_stns, A, H, Q, R, C, C_unweighted, G):\n",
        "    S = lambda i: np.sum([node.H.T @ np.linalg.inv(node.R) @ node.H for node in dkf.nodes[i].nbhrs], axis=0)\n",
        "\n",
        "    S_full = np.block([[np.zeros(A.shape) if i != j else S(j) for j in range(num_stns)] for i in range(num_stns)])\n",
        "    H_full = np.kron(np.eye(num_stns), H)\n",
        "    P_full = np.block([[np.zeros(Station_cov[0].shape) if i != j else Station_cov[j] for j in range(num_stns)] for i in range(num_stns)])\n",
        "    R_full = np.kron(np.eye(num_stns), R)\n",
        "\n",
        "    C_full = np.kron(C, np.eye(A.shape[0]))\n",
        "    A_full = np.kron(C_unweighted, np.eye(A.shape[0]))\n",
        "\n",
        "    F_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns), A)\n",
        "    G_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns), G[0])\n",
        "    D_i = C_full.T @ P_full @ A_full.T @ H_full.T @ np.linalg.inv(R_full)\n",
        "\n",
        "    term1 = (F_i @ prev_cov @ F_i.T)\n",
        "    term2 = G_i @ np.kron(np.ones((num_stns, num_stns)), Q) @ G_i.T\n",
        "    term3 = D_i @ R_full @ D_i.T\n",
        "\n",
        "    return term1 + term2 + term3\n",
        "\n",
        "\n",
        "# Function to run filters and return covariances\n",
        "def run_filters(W):\n",
        "    # print(W)\n",
        "    dt = 10\n",
        "\n",
        "    # define C\n",
        "    C_adj = np.array([[1, 1, 0, 0, 1],\n",
        "                      [1, 1, 1, 0, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [0, 0, 1, 1, 1],\n",
        "                      [1, 0, 0, 1, 1]])\n",
        "    C = C_adj * np.reshape(W, (5, 5))\n",
        "    C_unweighted = np.array([[1 if x != 0 else 0 for x in row] for row in C])\n",
        "    num_stns = len(C[0])\n",
        "\n",
        "    A = np.array([[1, dt, 0, 0], [0, 1, 0, 0],[0,0,1,dt], [0, 0, 0, 1]])\n",
        "    H = np.array([[1, 0, 0, 0],[0,0,1,0]])\n",
        "\n",
        "    dkf_state_size = len(A)\n",
        "    dkf_measure_size = len(H)\n",
        "\n",
        "    q = 0.001\n",
        "    Q = q*np.array([[(dt**3)/3, (dt**2)/2, 0, 0], [(dt**2)/2, dt, 0, 0],[0,0,(dt**3)/3,(dt**2)/2], [0, 0, (dt**2)/2, dt]])\n",
        "    R = np.array([[4,0],[0,4]])\n",
        "\n",
        "    A_kf = np.kron(np.eye(num_stns), A)\n",
        "    H_kf = np.kron(np.eye(num_stns), H)\n",
        "    Q_kf = np.kron(np.eye(num_stns), Q)\n",
        "    R_kf = np.kron(np.eye(num_stns), R)\n",
        "\n",
        "    kf_state_size = A_kf.shape[0]\n",
        "    kf_measure_size = R_kf.shape[0]\n",
        "\n",
        "    F = [A for _ in range(num_stns)]\n",
        "    G = [np.eye(A.shape[0]) for _ in range(num_stns)]\n",
        "    H_dkf = [H for _ in range(num_stns)]\n",
        "\n",
        "    Q_dkf = [Q for _ in range(num_stns)]\n",
        "    R_dkf = [R for _ in range(num_stns)]\n",
        "\n",
        "    procc_noise_kf = lambda : np.linalg.cholesky(Q_kf) @ np.random.normal(np.array([[0 for _ in range(kf_state_size)]]).T)\n",
        "    measure_noise_kf = lambda : np.linalg.cholesky(R_kf) @ np.random.normal(np.array([[0 for _ in range(kf_measure_size)]]).T)\n",
        "\n",
        "    measure_kf_to_dkf  = lambda z: [np.array([z[H.shape[0]*i + j] for j in range(H.shape[0])]) for i in range(num_stns)]\n",
        "    state_kf_to_dkf = lambda z: [np.array([z[A.shape[0]*i + j] for j in range(A.shape[0])]) for i in range(num_stns)]\n",
        "\n",
        "    # True Initial\n",
        "    x0_kf = np.array([[np.random.normal(0, np.sqrt(Q_kf[i, i])) for i in range(kf_state_size)]]).T\n",
        "\n",
        "    # Initial Estimate\n",
        "    x_kf = np.array([[np.random.normal(0, 5) for i in range(kf_state_size)]]).T\n",
        "    x_dkf = state_kf_to_dkf(x_kf)\n",
        "\n",
        "    P_kf = 10 * np.copy(Q_kf)\n",
        "    P_dkf = [10 * np.copy(Q) for _ in range(num_stns)]\n",
        "\n",
        "    kf = KalmanFilter(A=A_kf, H=H_kf, Q=Q_kf, R=R_kf, P=P_kf, x0=x0_kf)\n",
        "    dkf = DiffKF(C, F, G, H_dkf, R_dkf, Q_dkf, x_dkf, P_dkf)\n",
        "\n",
        "    iters = 60\n",
        "\n",
        "    truth = np.zeros((iters + 1, kf_state_size, 1))\n",
        "    truth[0] = x0_kf\n",
        "\n",
        "    measurements = np.zeros((iters + 1, kf_measure_size, 1))\n",
        "    measurements[0] = (H_kf @ x0_kf) + measure_noise_kf()\n",
        "\n",
        "    predictions_kf = np.zeros((iters, kf_state_size, 1))\n",
        "    predictions_dkf = np.zeros((iters, num_stns, A.shape[0], 1))\n",
        "\n",
        "    errors_kf = np.zeros((iters, kf_state_size, 1))\n",
        "    errors_dkf = np.zeros((iters, num_stns, A.shape[0], 1))\n",
        "\n",
        "    P_hist_kf = np.zeros((iters, kf_state_size, kf_state_size))\n",
        "    P_hist_dkf = np.zeros((iters, num_stns, A.shape[0], A.shape[0]))\n",
        "    full_system_P_hist = np.zeros((iters, kf_state_size, kf_state_size))\n",
        "    prev_cov = np.block([[np.zeros(P_dkf[0].shape) if i != j else dkf.nodes[i].P for j in range(num_stns)] for i in range(num_stns)])\n",
        "\n",
        "    for i in range(iters):\n",
        "        kf.update(measurements[i])\n",
        "        dkf.update(measure_kf_to_dkf(measurements[i]))\n",
        "\n",
        "        predictions_dkf[i] = [dkf.nodes[j].x for j in range(num_stns)]\n",
        "        errors_dkf[i] = [dkf.nodes[j].x - state_kf_to_dkf(truth[i])[j] for j in range(num_stns)]\n",
        "        station_covs = [dkf.nodes[j].P for j in range(num_stns)]\n",
        "        P_hist_dkf[i] = station_covs\n",
        "\n",
        "        prev_cov = get_diff_cov(prev_cov, station_covs, dkf, num_stns, A, H, Q, R, C, C_unweighted, G)\n",
        "        full_system_P_hist[i] = prev_cov\n",
        "\n",
        "        predictions_kf[i] = kf.x\n",
        "        errors_kf[i] = kf.x - truth[i]\n",
        "        P_hist_kf[i] = kf.P\n",
        "\n",
        "        kf.predict()\n",
        "        dkf.predict()\n",
        "\n",
        "        truth[i + 1] = A_kf @ x0_kf + procc_noise_kf()\n",
        "        measurements[i + 1] = H_kf @ truth[i + 1] + measure_noise_kf()\n",
        "\n",
        "    return (P_hist_kf[40], full_system_P_hist[40])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def generate_random_row_stochastic_matrix_template(template):\n",
        "    matrix = template.copy()\n",
        "    for i in range(matrix.shape[0]):\n",
        "        pos_indices = np.where(matrix[i] != 0)[0]\n",
        "        random_values = np.random.rand(len(pos_indices))\n",
        "        random_values /= random_values.sum()  # Normalize to make row sum to 1\n",
        "        matrix[i, pos_indices] = random_values\n",
        "    return matrix\n",
        "\n",
        "def generate_multiple_row_stochastic_matrices_template(n, template):\n",
        "    matrices = [generate_random_row_stochastic_matrix_template(template) for _ in range(n)]\n",
        "    return matrices\n",
        "\n",
        "\n",
        "# Template matrix\n",
        "template_matrix = np.array([[0.34, 0.33, 0, 0, 0.33],\n",
        "                            [0.33, 0.34, 0.33, 0, 0],\n",
        "                            [0, 0.33, 0.34, 0.33, 0],\n",
        "                            [0, 0, 0.33, 0.34, 0.33],\n",
        "                            [0.33, 0, 0, 0.33, 0.34]])\n",
        "\n",
        "# Generate 10 random matrices\n",
        "random_matrices = generate_multiple_row_stochastic_matrices_template(100, template_matrix)\n",
        "\n",
        "# Include the template matrix in the list of matrices\n",
        "all_matrices = [template_matrix] + random_matrices\n",
        "all_matrices = random_matrices\n",
        "\n",
        "# Compute the Bhattacharyya distance for each C value\n",
        "distances = []\n",
        "traces = []\n",
        "for i, C in enumerate(all_matrices):\n",
        "  reference_cov, cov = run_filters(C)\n",
        "  distance = bhattacharyya_distance(cov, reference_cov)\n",
        "  distances.append(distance)\n",
        "  trace = np.trace(cov)\n",
        "  traces.append(trace)\n",
        "\n",
        "# Plot the results\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(range(len(all_matrices)), distances, marker='o', label='Random Matrices')\n",
        "# plt.axhline(distances[0], color='r', linestyle='--', label='Template Matrix')\n",
        "# plt.xlabel('Matrix Index')\n",
        "# plt.ylabel('Bhattacharyya Distance')\n",
        "# plt.title('Bhattacharyya Distance vs. C Matrix Variations')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "print(all_matrices[np.argmin(traces)]) # Weight Matrix by minimizing the Trace (MEAN SQUARED ERROR)\n",
        "print(all_matrices[np.argmin(distances)]) # Weight Matrix by minimizing the Distance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOzhVOTjC0cX",
        "outputId": "4728942d-5099-4e80-944a-f5a05072712e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49203696 0.37366725 0.         0.         0.13429578]\n",
            " [0.3732009  0.36813132 0.25866779 0.         0.        ]\n",
            " [0.         0.29923988 0.37034628 0.33041385 0.        ]\n",
            " [0.         0.         0.32489282 0.09172924 0.58337794]\n",
            " [0.10296519 0.         0.         0.66588742 0.23114739]]\n",
            "[[0.01172641 0.20636788 0.         0.         0.78190571]\n",
            " [0.34863416 0.56091299 0.09045285 0.         0.        ]\n",
            " [0.         0.49883005 0.1045801  0.39658985 0.        ]\n",
            " [0.         0.         0.51421746 0.05997241 0.42581013]\n",
            " [0.42011027 0.         0.         0.51411257 0.06577716]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTICLE SWARM OPTIMIZATION - poor performance"
      ],
      "metadata": {
        "id": "h75sYBV6TJ69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BFGS"
      ],
      "metadata": {
        "id": "27R_psB4tTQF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}