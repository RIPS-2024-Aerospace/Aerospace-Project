{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "\n",
    "np.random.seed(163)\n",
    "\n",
    "%run \"DiffKf.ipynb\"\n",
    "%run \"KF.ipynb\""
   ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "id": "2b9PA5BBEBE0"
    },
    "outputs": [],
    "source": [
      "dt = 10\n",
      "\n",
      "C = np.array([[0.34,0.33, 0, 0, 0.33],[0.33,0.34,0.33,0,0],[0,0.33,0.34,0.33,0],[0,0,0.33,0.34,0.33],[0.33,0,0,0.33,0.34]])\n",
      "num_stns = len(C[0])\n",
      "\n",
      "A = np.array([[1, dt, 0, 0], [0, 1, 0, 0],[0,0,1,dt], [0, 0, 0, 1]])\n",
      "H = np.array([[1, 0, 0, 0],[0,0,1,0]])\n",
      "\n",
      "dkf_state_size = len(A)\n",
      "dkf_measure_size = len(H)\n",
      "\n",
      "q = 0.001\n",
      "Q = q*np.array([[(dt**3)/3, (dt**2)/2, 0, 0], [(dt**2)/2, dt, 0, 0],[0,0,(dt**3)/3,(dt**2)/2], [0, 0, (dt**2)/2, dt]])\n",
      "R = np.array([[4,0],[0,4]])\n",
      "\n",
      "A_kf = np.kron(np.eye(num_stns),A)\n",
      "H_kf = np.kron(np.eye(num_stns),H)\n",
      "Q_kf = np.kron(np.eye(num_stns),Q)\n",
      "R_kf = np.kron(np.eye(num_stns),R)\n",
      "\n",
      "kf_state_size = A_kf.shape[0]\n",
      "kf_measure_size = R_kf.shape[0]\n",
      "\n",
      "F = [A for _ in range(num_stns)]\n",
      "G = [np.eye(dkf_state_size) for _ in range(num_stns)]\n",
      "H_dkf = [H for _ in range(num_stns)]\n",
      "\n",
      "Q_dkf = [Q for _ in range(num_stns)]\n",
      "R_dkf = [R for _ in range(num_stns)]"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "id": "qxIQlGQSEBE0"
    },
    "outputs": [],
    "source": [
      "procc_noise_kf = lambda : np.linalg.cholesky(Q_kf) @ np.random.normal(np.array([[0 for _ in range(kf_state_size)]]).T)\n",
      "measure_noise_kf = lambda : np.linalg.cholesky(R_kf) @ np.random.normal(np.array([[0 for _ in range(kf_measure_size)]]).T)\n",
      "\n",
      "measure_kf_to_dkf  = lambda z: [np.array([z[dkf_measure_size*i + j] for j in range(dkf_measure_size)]) for i in range(num_stns)]\n",
      "state_kf_to_dkf = lambda z: [np.array([z[dkf_state_size*i + j] for j in range(dkf_state_size)]) for i in range(num_stns)]"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "id": "JQGtHSzmEBE0"
    },
    "outputs": [],
    "source": [
      "#True Initial\n",
      "x0_kf = np.array([[np.random.normal(0,np.sqrt(Q_kf[i,i])) for i in range(kf_state_size)]]).T\n",
      "\n",
      "\n",
      "#Initial Estimate\n",
      "x_kf = np.array([[np.random.normal(0,5) for i in range(kf_state_size)]]).T\n",
      "x_dkf = state_kf_to_dkf(x_kf)\n",
      "\n",
      "\n",
      "P_kf = 10*np.copy(Q_kf)\n",
      "P_dkf = [10*np.copy(Q) for _ in range(num_stns)]\n",
      "\n",
      "kf = KalmanFilter(A = A_kf,H = H_kf, Q = Q_kf, R = R_kf,P=P_kf,x0=x_kf)\n",
      "\n",
      "dkf = DiffKF(C,F,G,H_dkf,R_dkf,Q_dkf,x_dkf,P_dkf)"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "id": "UM5g1WNTEBE1",
      "outputId": "bd9af011-a69e-4116-c802-b109bd47c593"
    },
    "outputs": [],
    "source": [
      "\n",
      "iters = 60\n",
      "\n",
      "truth = np.zeros((iters+1,kf_state_size,1))\n",
      "truth[0] = x0_kf\n",
      "\n",
      "measurements = np.zeros((iters+1,kf_measure_size,1))\n",
      "measurements[0] = (H_kf @ x0_kf)+measure_noise_kf()\n",
      "\n",
      "\n",
      "predictions_kf = np.zeros((iters,kf_state_size,1))\n",
      "predictions_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
      "\n",
      "errors_kf = np.zeros((iters,kf_state_size,1))\n",
      "errors_dkf = np.zeros((iters,num_stns,dkf_state_size,1))\n",
      "\n",
      "P_hist_kf = np.zeros((iters,kf_state_size,kf_state_size))\n",
      "P_hist_dkf = np.zeros((iters, num_stns, dkf_state_size,dkf_state_size))\n",
      "\n",
      "for i in range(iters):\n",
      "\n",
      "    kf.update(measurements[i])\n",
      "    dkf.update(measure_kf_to_dkf(measurements[i]))\n",
      "\n",
      "    predictions_dkf[i] = [dkf.nodes[j].x for j in range(num_stns)]\n",
      "    errors_dkf[i] = [dkf.nodes[j].x-state_kf_to_dkf(truth[i])[j] for j in range(num_stns)]\n",
      "    P_hist_dkf[i] = [dkf.nodes[j].P for j in range(num_stns)]\n",
      "\n",
      "    predictions_kf[i] = kf.x\n",
      "    errors_kf[i] = kf.x-truth[i]\n",
      "    P_hist_kf[i] = kf.P\n",
      "\n",
      "    kf.predict()\n",
      "    dkf.predict()\n",
      "\n",
      "    truth[i+1] = A_kf@x0_kf + procc_noise_kf()\n",
      "    measurements[i+1] = H_kf @ truth[i+1] + measure_noise_kf()"
    ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
      "id": "acar0uEvEBE1",
      "outputId": "0c589620-f094-4829-c80a-54d79b82804f"
    },
    "outputs": [],
    "source": [
      "num_rows = -1*((-1*kf_state_size)//2)\n",
      "fig,axs = plt.subplots(num_rows,2, figsize=(14, 7*num_rows))\n",
      "t_hist_dkf = np.arange(0, dt*iters, dt)\n",
      "t_hist_kf = np.arange(dt/2, dt*iters, dt)\n",
      "\n",
      "for i in range(kf_state_size):\n",
      "    axs[i//2][i%2].plot(t_hist_dkf, errors_dkf[:, i//num_stns,i%dkf_state_size,0], 'k', label = f\"Diffusion Filter state {i+1} error\")\n",
      "    dkf_cov = np.sqrt(P_hist_dkf[:, i//num_stns,i%dkf_state_size,i%dkf_state_size])\n",
      "    axs[i//2][i%2].plot(np.vstack([t_hist_dkf[0], t_hist_dkf[0]]), np.vstack([dkf_cov[0], -dkf_cov[0]]), 'b--', label = \"Diffusion Filter 1-sigma bound\")\n",
      "    axs[i//2][i%2].plot(np.vstack([t_hist_dkf[1:], t_hist_dkf[1:]]), np.vstack([dkf_cov[1:], -dkf_cov[1:]]), 'b--')\n",
      "    kf_error = errors_kf[:, i,0]\n",
      "    kf_cov = np.sqrt(P_hist_kf[:, i, i])\n",
      "    axs[i//2][i%2].plot(t_hist_kf, kf_error,'m',label=f'Centralized Filter state {i+1} error')\n",
      "    axs[i//2][i%2].plot(np.vstack([t_hist_kf[0], t_hist_kf[0]]), np.vstack([kf_cov[0], -kf_cov[0]]), 'r--',label = \"Centralized Bias 1-sigma bound\")\n",
      "    axs[i//2][i%2].plot(np.vstack([t_hist_kf[1:], t_hist_kf[1:]]), np.vstack([kf_cov[1:], -kf_cov[1:]]), 'r--')\n",
      "    axs[i//2][i%2].legend()\n",
      "    axs[i//2][i%2].set_title(\"State Element \"+str(i+1)+\" Error\", fontsize = 20)\n",
      "    axs[i//2][i%2].set_xlabel(\"Time\", fontsize = 18)\n",
      "    axs[i//2][i%2].set_ylabel(\"Estimate vs True Bias Error\", fontsize = 18)"
    ]
  },
  {
    "cell_type": "code",
    "source": [
      "def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
      "    # mu1 = mean of diffusion KF\n",
      "    # mu2 = mean of centralized KF\n",
      "    # Sigma1 = covariance of diffusion KF\n",
      "    # Sigma2 = covariance of centralized KF\n",
      "    Sigma = (Sigma1 + Sigma2) / 2\n",
      "    inv_Sigma = np.linalg.inv(Sigma)\n",
      "\n",
      "    term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
      "    term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
      "\n",
      "    return term1 + term2\n",
      "\n",
      "# centralized\n",
      "mu2 = kf.x\n",
      "Sigma2 = kf.P\n",
      "\n",
      "# diffusion\n",
      "# mu1\n",
      "n_i1 = np.random.normal(loc=0, scale=1, size=m)\n",
      "v_i = np.random.normal(loc=0, scale=1, size=m)\n",
      "tilde_x_i_i1 = truth[0]\n",
      "\n",
      "\n",
      "S_i = np.sum(np.dot(H_n, np.dot(np.linalg.inv(R_dkf), H_n)))\n",
      "\n",
      "# compute the state (equation 30)\n",
      "term1 = np.dot(C.T, np.dot(np.identity(20) - np.dot(P_dkf, S_i), np.dot(np.kron(np.identity(20), F), tilde_x_i_i1)))\n",
      "term2 = np.dot(np.kron(np.identity(20), G), np.kron(np.ones((20,20)), n_i1))\n",
      "term3 = np.dot(C.T, np.dot(P_dkf, np.dot(H_n.T, np.dot(np.linalg.inv(R_dkf), v_i))))\n",
      "mu1 = term1 + term2 - term3\n",
      "\n",
      "# Sigma1\n",
      "# compute the covariance (equation 32)\n",
      "F_chi_i = np.dot(C.T, np.dot(np.identity(2) - np.dot(P_dkf, S_i), np.kron(np.identity(1), F)))\n",
      "G_i = np.dot(C.T, np.dot(np.identity(2) - np.dot(P_dkf, S_i), np.kron(np.identity(1), G)))\n",
      "D_i = np.dot(C.T, np.dot(P_dkf, np.dot(H_n.T, np.linalg.inv(R_dkf))))\n",
      "term1 = np.dot(F, np.dot(P_hist_dkf, F_chi_i.T))\n",
      "term2 = np.dot(G_i, np.dot(np.kron(np.ones((1, 1)), Q_dkf), G_i.T))\n",
      "term3 = np.dot(D_i, np.dot(R_dkf, D_i.T))\n",
      "\n",
      "Sigma1 = term1 + term2 + term3\n",
      "\n",
      "# compute the Bhattacharya distance\n",
      "print(\"The Bhattacharya Distance is: \", bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2))"
    ],
    "metadata": {
      "id": "_EEVdgABEFzp"
    },
    "execution_count": null,
    "outputs": []
  }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  }
  "nbformat": 4,
  "nbformat_minor": 0
}
