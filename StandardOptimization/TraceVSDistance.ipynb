{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This code performs a Monte Carlo simulation to compare two optimization strategies for selecting diffusion weights in a Diffusion Kalman Filter (DKF) network.\n",
        "\n",
        "The two strategies involve minimizing the trace of the covariance matrix (which relates to the Mean Squared Error) and minimizing the Bhattacharyya distance (a measure of the similarity between two distributions). The results help identify the optimal set of weights that either minimize estimation error between the DKF and a centralized Kalman Filter (CKF)."
      ],
      "metadata": {
        "id": "ku-TVzhh8Zqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RIPS-2024-Aerospace/Aerospace-Project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IXu0aYVeFGL",
        "outputId": "be067a9b-a7c1-46c2-9aba-ba8842bf8132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aerospace-Project'...\n",
            "remote: Enumerating objects: 410, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 410 (delta 100), reused 68 (delta 54), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (410/410), 26.23 MiB | 6.81 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGnG9B_pd-e7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "\n",
        "np.random.seed(163)\n",
        "\n",
        "# replace with file paths\n",
        "# %run \"DiffKf.ipynb\"\n",
        "# %run \"KF.ipynb\"\n",
        "%run \"/content/Aerospace-Project/Standard Filters/DiffKf.ipynb\"\n",
        "%run \"/content/Aerospace-Project/Standard Filters/KF.ipynb\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MONTE CARLO: COMPARISON OF MINIMIZING TRACE VS MINIMIZING B DISTANCE"
      ],
      "metadata": {
        "id": "WiIHJPLNhrJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "\n",
        "# Bhattacharyya distance function\n",
        "# def bhattacharyya_distance(mu1, mu2, Sigma1, Sigma2):\n",
        "#     Sigma = (Sigma1 + Sigma2) / 2\n",
        "#     inv_Sigma = np.linalg.inv(Sigma)\n",
        "#     term1 = 1/8 * np.dot(np.dot((mu1 - mu2).T, inv_Sigma), (mu1 - mu2))\n",
        "#     term2 = 1/2 * np.log(np.linalg.det(Sigma) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2)))\n",
        "#     return term1 + term2\n",
        "\n",
        "\n",
        "# since the means are 0, I'm getting rid of the first term\n",
        "def bhattacharyya_distance(Sigma1, Sigma2):\n",
        "    Sigma_mean = (Sigma1 + Sigma2) / 2\n",
        "    term1 = np.log(np.linalg.det(Sigma_mean) / np.sqrt(np.linalg.det(Sigma1) * np.linalg.det(Sigma2))) / 2\n",
        "    return term1\n",
        "\n",
        "# Function to get diffusion covariance\n",
        "def get_diff_cov(prev_cov, Station_cov, dkf, num_stns, A, H, Q, R, C, C_unweighted, G):\n",
        "    S = lambda i: np.sum([node.H.T @ np.linalg.inv(node.R) @ node.H for node in dkf.nodes[i].nbhrs], axis=0)\n",
        "\n",
        "    S_full = np.block([[np.zeros(A.shape) if i != j else S(j) for j in range(num_stns)] for i in range(num_stns)])\n",
        "    H_full = np.kron(np.eye(num_stns), H)\n",
        "    P_full = np.block([[np.zeros(Station_cov[0].shape) if i != j else Station_cov[j] for j in range(num_stns)] for i in range(num_stns)])\n",
        "    R_full = np.kron(np.eye(num_stns), R)\n",
        "\n",
        "    C_full = np.kron(C, np.eye(A.shape[0]))\n",
        "    A_full = np.kron(C_unweighted, np.eye(A.shape[0]))\n",
        "\n",
        "    F_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns), A)\n",
        "    G_i = C_full.T @ (np.eye(S_full.shape[1]) - (P_full @ S_full)) @ np.kron(np.eye(num_stns), G[0])\n",
        "    D_i = C_full.T @ P_full @ A_full.T @ H_full.T @ np.linalg.inv(R_full)\n",
        "\n",
        "    term1 = (F_i @ prev_cov @ F_i.T)\n",
        "    term2 = G_i @ np.kron(np.ones((num_stns, num_stns)), Q) @ G_i.T\n",
        "    term3 = D_i @ R_full @ D_i.T\n",
        "\n",
        "    return term1 + term2 + term3\n",
        "\n",
        "\n",
        "# Function to run filters and return covariances\n",
        "def run_filters(W):\n",
        "    # print(W)\n",
        "    dt = 10\n",
        "\n",
        "    # define C\n",
        "    C_adj = np.array([[1, 1, 0, 0, 1],\n",
        "                      [1, 1, 1, 0, 0],\n",
        "                      [0, 1, 1, 1, 0],\n",
        "                      [0, 0, 1, 1, 1],\n",
        "                      [1, 0, 0, 1, 1]])\n",
        "    C = C_adj * np.reshape(W, (5, 5))\n",
        "    C_unweighted = np.array([[1 if x != 0 else 0 for x in row] for row in C])\n",
        "    num_stns = len(C[0])\n",
        "\n",
        "    A = np.array([[1, dt, 0, 0], [0, 1, 0, 0],[0,0,1,dt], [0, 0, 0, 1]])\n",
        "    H = np.array([[1, 0, 0, 0],[0,0,1,0]])\n",
        "\n",
        "    dkf_state_size = len(A)\n",
        "    dkf_measure_size = len(H)\n",
        "\n",
        "    # change q to see how it affects the trace and B distance\n",
        "    q = 0.004\n",
        "    Q = q*np.array([[(dt**3)/3, (dt**2)/2, 0, 0], [(dt**2)/2, dt, 0, 0],[0,0,(dt**3)/3,(dt**2)/2], [0, 0, (dt**2)/2, dt]])\n",
        "    R = np.array([[4,0],[0,4]])\n",
        "\n",
        "    A_kf = np.kron(np.eye(num_stns), A)\n",
        "    H_kf = np.kron(np.eye(num_stns), H)\n",
        "    Q_kf = np.kron(np.eye(num_stns), Q)\n",
        "    R_kf = np.kron(np.eye(num_stns), R)\n",
        "\n",
        "    kf_state_size = A_kf.shape[0]\n",
        "    kf_measure_size = R_kf.shape[0]\n",
        "\n",
        "    F = [A for _ in range(num_stns)]\n",
        "    G = [np.eye(A.shape[0]) for _ in range(num_stns)]\n",
        "    H_dkf = [H for _ in range(num_stns)]\n",
        "\n",
        "    Q_dkf = [Q for _ in range(num_stns)]\n",
        "    R_dkf = [R for _ in range(num_stns)]\n",
        "\n",
        "    procc_noise_kf = lambda : np.linalg.cholesky(Q_kf) @ np.random.normal(np.array([[0 for _ in range(kf_state_size)]]).T)\n",
        "    measure_noise_kf = lambda : np.linalg.cholesky(R_kf) @ np.random.normal(np.array([[0 for _ in range(kf_measure_size)]]).T)\n",
        "\n",
        "    measure_kf_to_dkf  = lambda z: [np.array([z[H.shape[0]*i + j] for j in range(H.shape[0])]) for i in range(num_stns)]\n",
        "    state_kf_to_dkf = lambda z: [np.array([z[A.shape[0]*i + j] for j in range(A.shape[0])]) for i in range(num_stns)]\n",
        "\n",
        "    # True Initial\n",
        "    x0_kf = np.array([[np.random.normal(0, np.sqrt(Q_kf[i, i])) for i in range(kf_state_size)]]).T\n",
        "\n",
        "    # Initial Estimate\n",
        "    x_kf = np.array([[np.random.normal(0, 5) for i in range(kf_state_size)]]).T\n",
        "    x_dkf = state_kf_to_dkf(x_kf)\n",
        "\n",
        "    P_kf = 10 * np.copy(Q_kf)\n",
        "    P_dkf = [10 * np.copy(Q) for _ in range(num_stns)]\n",
        "\n",
        "    kf = KalmanFilter(A=A_kf, H=H_kf, Q=Q_kf, R=R_kf, P=P_kf, x0=x0_kf)\n",
        "    dkf = DiffKF(C, F, G, H_dkf, R_dkf, Q_dkf, x_dkf, P_dkf)\n",
        "\n",
        "    iters = 60\n",
        "\n",
        "    truth = np.zeros((iters + 1, kf_state_size, 1))\n",
        "    truth[0] = x0_kf\n",
        "\n",
        "    measurements = np.zeros((iters + 1, kf_measure_size, 1))\n",
        "    measurements[0] = (H_kf @ x0_kf) + measure_noise_kf()\n",
        "\n",
        "    predictions_kf = np.zeros((iters, kf_state_size, 1))\n",
        "    predictions_dkf = np.zeros((iters, num_stns, A.shape[0], 1))\n",
        "\n",
        "    errors_kf = np.zeros((iters, kf_state_size, 1))\n",
        "    errors_dkf = np.zeros((iters, num_stns, A.shape[0], 1))\n",
        "\n",
        "    P_hist_kf = np.zeros((iters, kf_state_size, kf_state_size))\n",
        "    P_hist_dkf = np.zeros((iters, num_stns, A.shape[0], A.shape[0]))\n",
        "    full_system_P_hist = np.zeros((iters, kf_state_size, kf_state_size))\n",
        "    prev_cov = np.block([[np.zeros(P_dkf[0].shape) if i != j else dkf.nodes[i].P for j in range(num_stns)] for i in range(num_stns)])\n",
        "\n",
        "    for i in range(iters):\n",
        "        kf.update(measurements[i])\n",
        "        dkf.update(measure_kf_to_dkf(measurements[i]))\n",
        "\n",
        "        predictions_dkf[i] = [dkf.nodes[j].x for j in range(num_stns)]\n",
        "        errors_dkf[i] = [dkf.nodes[j].x - state_kf_to_dkf(truth[i])[j] for j in range(num_stns)]\n",
        "        station_covs = [dkf.nodes[j].P for j in range(num_stns)]\n",
        "        P_hist_dkf[i] = station_covs\n",
        "\n",
        "        prev_cov = get_diff_cov(prev_cov, station_covs, dkf, num_stns, A, H, Q, R, C, C_unweighted, G)\n",
        "        full_system_P_hist[i] = prev_cov\n",
        "\n",
        "        predictions_kf[i] = kf.x\n",
        "        errors_kf[i] = kf.x - truth[i]\n",
        "        P_hist_kf[i] = kf.P\n",
        "\n",
        "        kf.predict()\n",
        "        dkf.predict()\n",
        "\n",
        "        truth[i + 1] = A_kf @ x0_kf + procc_noise_kf()\n",
        "        measurements[i + 1] = H_kf @ truth[i + 1] + measure_noise_kf()\n",
        "\n",
        "    return (P_hist_kf[40], full_system_P_hist[40])\n",
        "\n",
        "# Function to generate a random row-stochastic matrix based on a template\n",
        "def generate_random_row_stochastic_matrix_template(template):\n",
        "    matrix = template.copy()\n",
        "    for i in range(matrix.shape[0]):\n",
        "        pos_indices = np.where(matrix[i] != 0)[0]\n",
        "        random_values = np.random.rand(len(pos_indices))\n",
        "        random_values /= random_values.sum()  # Normalize to make row sum to 1\n",
        "        matrix[i, pos_indices] = random_values\n",
        "    return matrix\n",
        "\n",
        "# Function to generate multiple row-stochastic matrices based on a template\n",
        "def generate_multiple_row_stochastic_matrices_template(n, template):\n",
        "    matrices = [generate_random_row_stochastic_matrix_template(template) for _ in range(n)]\n",
        "    return matrices\n",
        "\n",
        "\n",
        "# Template matrix\n",
        "template_matrix = np.array([[0.34, 0.33, 0, 0, 0.33],\n",
        "                            [0.33, 0.34, 0.33, 0, 0],\n",
        "                            [0, 0.33, 0.34, 0.33, 0],\n",
        "                            [0, 0, 0.33, 0.34, 0.33],\n",
        "                            [0.33, 0, 0, 0.33, 0.34]])\n",
        "\n",
        "# Generate 10 random matrices\n",
        "random_matrices = generate_multiple_row_stochastic_matrices_template(100, template_matrix)\n",
        "\n",
        "# Include the template matrix in the list of matrices\n",
        "all_matrices = [template_matrix] + random_matrices\n",
        "\n",
        "# Compute the Bhattacharyya distance for each C value\n",
        "distances = []\n",
        "traces = []\n",
        "traces_kf = []\n",
        "for i, C in enumerate(all_matrices):\n",
        "  reference_cov, cov = run_filters(C)\n",
        "  distance = bhattacharyya_distance(cov, reference_cov)\n",
        "  distances.append(distance)\n",
        "  trace = np.trace(cov)\n",
        "  traces.append(trace)\n",
        "  trace_kf = np.trace(reference_cov)\n",
        "  traces_kf.append(trace_kf)\n",
        "\n",
        "# Plot the results\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(range(len(all_matrices)), distances, marker='o', label='Random Matrices')\n",
        "# plt.axhline(distances[0], color='r', linestyle='--', label='Template Matrix')\n",
        "# plt.xlabel('Matrix Index')\n",
        "# plt.ylabel('Bhattacharyya Distance')\n",
        "# plt.title('Bhattacharyya Distance vs. C Matrix Variations')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "print(\"Optimal weights by minimizing trace\")\n",
        "print(all_matrices[np.argmin(traces)]) # Weight Matrix by minimizing the Trace (MEAN SQUARED ERROR)\n",
        "print()\n",
        "print(\"Optimal weights by minimizing Bhattacharya Distance\")\n",
        "print(all_matrices[np.argmin(distances)]) # Weight Matrix by minimizing the Distance\n",
        "print()\n",
        "print(traces_kf) # traces of CKF\n",
        "print(traces) # traces of DKF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOzhVOTjC0cX",
        "outputId": "1733e16d-8f40-4e43-a8d2-ca83e55d0069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal weights by minimizing trace\n",
            "[[0.34 0.33 0.   0.   0.33]\n",
            " [0.33 0.34 0.33 0.   0.  ]\n",
            " [0.   0.33 0.34 0.33 0.  ]\n",
            " [0.   0.   0.33 0.34 0.33]\n",
            " [0.33 0.   0.   0.33 0.34]]\n",
            "\n",
            "Optimal weights by minimizing Bhattacharya Distance\n",
            "[[0.10404715 0.88679962 0.         0.         0.00915323]\n",
            " [0.62430303 0.29078548 0.08491149 0.         0.        ]\n",
            " [0.         0.14320133 0.19211991 0.66467876 0.        ]\n",
            " [0.         0.         0.38717682 0.2128951  0.39992809]\n",
            " [0.07824148 0.         0.         0.16561947 0.75613906]]\n",
            "\n",
            "[30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977, 30.683245687002977]\n",
            "[89.00830699683131, 108.87437726384968, 116.70510062254407, 124.12208454980525, 96.80658437504508, 96.2810384493517, 111.06268825421016, 121.62340367842174, 92.67511766882296, 91.30843867230735, 98.79879728653076, 92.74526700633268, 92.5825367119748, 95.4044609704413, 99.65266436182631, 98.459750314569, 105.51389881186132, 100.51951746036043, 97.83030851261277, 103.23765874982124, 104.97504284838394, 95.27884432819907, 97.57533475381898, 96.16299681070981, 99.13386545651804, 101.01609191942848, 112.01746812728288, 90.92429389099698, 113.80685305181053, 98.76843193064667, 109.41724271177222, 107.60181833791202, 91.41098148066436, 104.11272710832921, 100.9660233869846, 96.47949206083732, 100.91325059555285, 96.15710986219625, 95.48411964987315, 110.76235032492755, 94.55596801892423, 99.01667872725903, 97.5141609229149, 112.73237679491852, 132.1779307057577, 94.47852239550147, 109.81303652458612, 116.54088647941875, 99.82924614744755, 165.2272040923966, 94.46628899278409, 106.51206639538648, 120.88504619678118, 97.07492106050256, 105.63482090343608, 98.10169171256845, 99.07912426055957, 95.43848758751679, 101.52851391820803, 95.48884317527471, 94.94485284740009, 95.84109888592798, 100.47347355763438, 109.4093432092359, 113.72223620192769, 90.62363507822499, 123.51506452877341, 93.41966461601811, 107.12790354760936, 110.51789214242254, 110.35294474073189, 128.42333518150912, 114.0507610086121, 108.01492409109497, 116.91695640069314, 110.12037329950496, 102.00296728019211, 93.00810190143667, 94.8432610144833, 113.07942036296643, 116.65297983026808, 105.55540398330356, 96.08408178454293, 92.52530389087941, 103.93478930317026, 92.5697063088615, 118.49618080247737, 104.97036209950457, 105.01922251765305, 119.8444787135061, 105.17390071404228, 98.060941965814, 110.23090429050725, 109.39378294705494, 138.4403297477653, 102.01502098914877, 97.66277161974637, 93.13233358238381, 109.00920941774032, 150.50384401985028, 98.5534719002702]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PARTICLE SWARM OPTIMIZATION - poor performance"
      ],
      "metadata": {
        "id": "h75sYBV6TJ69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BFGS"
      ],
      "metadata": {
        "id": "27R_psB4tTQF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}