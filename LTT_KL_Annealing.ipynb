{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlbevPf34VKOkmUBITCD4S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RIPS-2024-Aerospace/Aerospace-Project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4JVe1nn0KI7",
        "outputId": "920ad65f-897c-446d-8c48-df8ae5a33e7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Aerospace-Project'...\n",
            "remote: Enumerating objects: 446, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 446 (delta 116), reused 82 (delta 55), pack-reused 269\u001b[K\n",
            "Receiving objects: 100% (446/446), 30.88 MiB | 10.98 MiB/s, done.\n",
            "Resolving deltas: 100% (206/206), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "\n",
        "np.random.seed(29)\n",
        "\n",
        "%run ./Aerospace-Project/DiffusionLunarKF.ipynb\n",
        "%run ./Aerospace-Project/CentralizedLunarKF.ipynb\n",
        "%run ./Aerospace-Project/FilterComparison.ipynb"
      ],
      "metadata": {
        "id": "N21KPxdZ0Lax"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code from the testFilterComparisonFile for example data\n",
        "C = np.array([[0.2,0.2,0.2,0.2,0.2], [0.5, 0.5, 0, 0,0], [0.5, 0, 0.5, 0,0], [0.5,0,0, 0.5,0],[0.5,0,0,0,0.5]])\n",
        "C_ckf = 0.2*np.ones((5,5))\n",
        "D = np.array([[3,3,3,3,3], [3, 3, 0, 0,0], [3, 0, 3, 0,0], [3,0,0, 3,0],[3,0,0,0,3]])\n",
        "D_ckf = 3*np.ones((5,5))\n",
        "n = len(C)\n",
        "\n",
        "true_biases = np.array([[np.random.normal(0,np.sqrt(12/(c**2))) for _ in range(n)]]).T\n",
        "true_drifts = np.array([[np.random.normal(0,np.sqrt(0.1/(c**2))) for _ in range(n)]]).T\n",
        "# true_drifts = np.array([[0 for _ in range(n)]]).T\n",
        "\n",
        "F = np.array([[1,dt],[0,1]])\n",
        "F_full = np.kron(np.eye(n),F)\n",
        "\n",
        "def get_station_truth(x,id):\n",
        "    return np.array([[x[2*id][0]],[x[2*id+1][0]]])\n",
        "\n",
        "x = c*np.vstack(tuple([np.array([true_biases[i],true_drifts[i]]) for i in range(n)]))\n",
        "\n",
        "# random initial estimates for each node\n",
        "\n",
        "x0 = [np.array([[np.random.normal(0,np.sqrt(12))],[np.random.normal(0,np.sqrt(0.1))]]) for i in range(n)]\n",
        "\n",
        "\n",
        "P = [100*np.copy(R(1)) for _ in range(n)]\n",
        "\n",
        "stations = [Station(i) for i in range(n)]\n",
        "stations_ckf = [Station(i) for i in range(n)]\n",
        "filter_initialize(stations,D,x0,P)\n",
        "\n",
        "filter_initialize(stations_ckf,D_ckf,x0,P)\n",
        "\n",
        "iterations = 200\n",
        "\n",
        "# num_msmts = np.random.randint(0,10,(iterations,5))\n",
        "num_msmts = np.array([[0,2,2,2,2] for _ in range(iterations)])\n",
        "\n",
        "filter_outputs = run_both_filters(iterations, num_msmts,C,F_full,stations,stations_ckf, x)\n",
        "\n",
        "errors_df,errors_cf,P_hist_cf,P_hist_df,truth,measurements = filter_outputs"
      ],
      "metadata": {
        "id": "XGxaJ5OMpI4f"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cost function & optimize.\n",
        "\n",
        "# first define kullback leibler divergence value (correct)\n",
        "def kld(mu1, mu2, Sigma1, Sigma2):\n",
        "  k = len(mu1)\n",
        "  inv_Sigma2 = np.linalg.inv(Sigma2)\n",
        "  term1 = np.trace(np.dot(inv_Sigma2, Sigma1))\n",
        "  term2 = np.dot(np.dot((mu2 - mu1).T, inv_Sigma2), (mu2 - mu1))\n",
        "  term3 = np.log(np.linalg.det(Sigma2) / np.linalg.det(Sigma1))\n",
        "  return 0.5 * (term1 + term2 - k + term3)\n",
        "\n",
        "# now use kld for the cost function -- this function has wrong values but inputs are the means and covariances so fix this!\n",
        "def cost_function_kld(truth, errors_df, errors_cf, P_hist_df, P_hist_cf):\n",
        "  # values\n",
        "  Sigma_df = np.block(P_hist_df[-1])\n",
        "  Sigma_cf = np.array(P_hist_cf[-1])\n",
        "\n",
        "  #zero values\n",
        "  #mu_df = np.zeros(Sigma_df.shape[0])\n",
        "  #mu_cf = np.zeros(Sigma_cf.shape[0])\n",
        "  # Using the difference between truth and errors as mean\n",
        "  mu_df = truth[-1].flatten() - errors_df[-1].flatten()\n",
        "  mu_cf = truth[-1].flatten() - errors_cf[-1].flatten()\n",
        "\n",
        "  kld_value = kld(mu_df, mu_cf, Sigma_df, Sigma_cf)\n",
        "  return kld_value\n",
        "\n",
        "# add in a station weights thing to Station class, not sure if this is optimal though to store weights. checking to see if there is a better way. better way?\n",
        "#Station.nbhr_weights = {}\n",
        "\n",
        "# define the cost_function - sets up the weights\n",
        "def cost_function(weights):\n",
        "  n = len(stations)\n",
        "  weight_index = 0\n",
        "  weights_dict = {i: {} for i in range(n)}\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if C_adj[i, j] == 1:\n",
        "        #stations[i].nbhr_weights[j] = weights[weight_index]\n",
        "        weights_dict[i][j] = weights[weight_index]\n",
        "        weight_index += 1\n",
        "    weight_index = 0\n",
        "\n",
        "# define the wrapper cost function - plugs in the updated values into cost_kld to compute kld for each set of weights\n",
        "def wrapper_cost_function(weights):\n",
        "  cost_function(weights)\n",
        "  # re-run run_both_filters\n",
        "\n",
        "  #filter_outputs = run_both_filters(iterations, num_msmts, C, P_prev, F_full, stations, kf, x)\n",
        "  filter_outputs = run_both_filters(iterations, num_msmts, C, F_full, stations, stations_ckf, x)\n",
        "\n",
        "  #full_P_hist_df, errors_df, errors_cf, P_hist_cf, P_hist_df, truth, measurements, predictions_cf, predictions_df = filter_outputs\n",
        "  errors_df, errors_cf, P_hist_cf, P_hist_df, truth, measurements = filter_outputs\n",
        "\n",
        "  return cost_function_kld(truth, errors_df, errors_cf, P_hist_df, P_hist_cf)\n",
        "\n",
        "# simulated annealing\n",
        "def simulated_annealing(initial_weights, iterations, temperature, cooling_rate):\n",
        "  current_weights = initial_weights\n",
        "  best_weights = np.copy(initial_weights)\n",
        "  current_cost = cost_function(current_weights)\n",
        "  best_cost = current_cost\n",
        "\n",
        "  for i in range(iterations):\n",
        "    candidate_weights = current_weights + np.random.normal(0, 0.1, size=current_weights.shape) # add noise\n",
        "    candidate_weights = np.abs(candidate_weights) # all positive\n",
        "    candidate_weights /= np.sum(candidate_weights, axis=1, keepdims=True) # sum to 1\n",
        "\n",
        "    candidate_cost = wrapper_cost_function(candidate_weights) # compute the cost of the new weights\n",
        "\n",
        "    # check if the cost is lower or random is less than difference/temp by sim anneal alg\n",
        "    if candidate_cost < current_cost or random.uniform(0, 1) < np.exp((current_cost - candidate_cost) / temperature):\n",
        "      current_weights = candidate_weights\n",
        "      current_cost = candidate_cost\n",
        "\n",
        "      if current_cost < best_cost:\n",
        "        best_weights = current_weights\n",
        "        best_cost = current_cost\n",
        "\n",
        "    # decrease temperature\n",
        "    temperature *= cooling_rate\n",
        "\n",
        "  return best_weights, best_cost\n",
        "\n",
        "# Provided initial weights (C matrix flattened)\n",
        "initial_weights = np.array([[0.34, 0.33, 0, 0, 0.33],\n",
        "                            [0.33, 0.34, 0.33, 0, 0],\n",
        "                            [0, 0.33, 0.34, 0.33, 0],\n",
        "                            [0, 0, 0.33, 0.34, 0.33],\n",
        "                            [0.33, 0, 0, 0.33, 0.34]])\n",
        "\n",
        "# Adjacency matrix indicating possible connections (1 if there is a connection, 0 otherwise)\n",
        "C_adj = np.array([[1, 1, 0, 0, 1],\n",
        "                  [1, 1, 1, 0, 0],\n",
        "                  [0, 1, 1, 1, 0],\n",
        "                  [0, 0, 1, 1, 1],\n",
        "                  [1, 0, 0, 1, 1]])\n",
        "# Perform simulated annealing\n",
        "optimal_weights, optimal_cost = simulated_annealing(initial_weights, iterations=1000, temperature=10.0, cooling_rate=0.99)\n",
        "\n",
        "print(f\"Optimal Weights: {optimal_weights.reshape(C_adj.shape)}\")\n",
        "print(f\"Optimal Cost: {optimal_cost}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "zAMsP3K-fLTJ",
        "outputId": "7a1fb45d-061c-4e7d-e317-ff81df85145a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "shapes (10,) and (5,2,2) not aligned: 10 (dim 0) != 2 (dim 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-60e23c72ac2f>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m                   [1, 0, 0, 1, 1]])\n\u001b[1;32m     98\u001b[0m \u001b[0;31m# Perform simulated annealing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0moptimal_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimal_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulated_annealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcooling_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Optimal Weights: {optimal_weights.reshape(C_adj.shape)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-60e23c72ac2f>\u001b[0m in \u001b[0;36msimulated_annealing\u001b[0;34m(initial_weights, iterations, temperature, cooling_rate)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mcandidate_weights\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sum to 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mcandidate_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_cost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute the cost of the new weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# check if the cost is lower or random is less than difference/temp by sim anneal alg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-60e23c72ac2f>\u001b[0m in \u001b[0;36mwrapper_cost_function\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[0merrors_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_hist_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_hist_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcost_function_kld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_hist_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_hist_cf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# simulated annealing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-60e23c72ac2f>\u001b[0m in \u001b[0;36mcost_function_kld\u001b[0;34m(truth, errors_df, errors_cf, P_hist_df, P_hist_cf)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mmu_cf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtruth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merrors_cf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mkld_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_cf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma_cf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mkld_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-60e23c72ac2f>\u001b[0m in \u001b[0;36mkld\u001b[0;34m(mu1, mu2, Sigma1, Sigma2)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minv_Sigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mterm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_Sigma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mterm2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_Sigma2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmu2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mterm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSigma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: shapes (10,) and (5,2,2) not aligned: 10 (dim 0) != 2 (dim 1)"
          ]
        }
      ]
    }
  ]
}